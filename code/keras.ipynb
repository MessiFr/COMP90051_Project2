{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy import mean\n",
    "import pandas as pd\n",
    "import json\n",
    "from numpy import std\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "     X :  (25793, 26147)\n",
      "     y :  (25793, 100)\n",
      "Test:\n",
      "     X :  (800, 26147)\n"
     ]
    }
   ],
   "source": [
    "# read train data and test data\n",
    "f_train = open(\"../data/train.json\", 'r')\n",
    "train_data = json.load(f_train)\n",
    "\n",
    "f_test = open(\"../data/test.json\", 'r')\n",
    "test_data = json.load(f_test)\n",
    "\n",
    "def get_attr_matrix(data):\n",
    "    n_samples = len(data)\n",
    "    n_features = 5000 -1 \n",
    "\n",
    "    # get abstract & title feature\n",
    "    wmatrix = np.ndarray([n_samples, n_features])\n",
    "    wmatrix.fill(0)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        instance = data[i]\n",
    "        for title in instance['title']:\n",
    "            wmatrix[i, title-1] += 1\n",
    "        for abstract in instance['abstract']:\n",
    "            wmatrix[i, abstract-1] += 1\n",
    "\n",
    "    # get venue feature\n",
    "    vmatrix = np.ndarray([n_samples, 1])\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        venue = data[i]['venue']\n",
    "        \n",
    "        if venue:\n",
    "            vmatrix[i, ] = venue\n",
    "        else:\n",
    "            vmatrix[i, ] = -1\n",
    "\n",
    "    # get year feature\n",
    "    ymatrix = np.ndarray([n_samples, 1])\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        year = data[i]['year']\n",
    "        \n",
    "        if year:\n",
    "            ymatrix[i, ] = year\n",
    "        else:\n",
    "            ymatrix[i, ] = -1\n",
    "            \n",
    "    return np.concatenate((wmatrix, vmatrix, ymatrix), axis=1)\n",
    "\n",
    "attr_matrix = get_attr_matrix(train_data)\n",
    "attr_matrix_test = get_attr_matrix(test_data)\n",
    "\n",
    "def handle_authors(data, key=\"author\"):\n",
    "\n",
    "    n_samples = len(data)\n",
    "\n",
    "    # prolific authors \n",
    "    y = np.ndarray([n_samples, 100])\n",
    "    y.fill(0)\n",
    "\n",
    "    # get co-author matrix\n",
    "    amatrix = np.ndarray([n_samples, 21245 - 100 + 1])\n",
    "    amatrix.fill(0)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        authors = data[i][key]\n",
    "        \n",
    "        for au in authors:\n",
    "            if au < 100:\n",
    "                \n",
    "                y[i, au] += 1\n",
    "            else:\n",
    "                amatrix[i, au - 100] += 1\n",
    "\n",
    "    return amatrix, y\n",
    "\n",
    "amatrix, y = handle_authors(train_data, key=\"authors\")\n",
    "\n",
    "amatrix_test, _ = handle_authors(test_data, key=\"coauthors\")\n",
    "\n",
    "X = np.concatenate((attr_matrix, amatrix), axis=1)\n",
    "X_kaggle = np.concatenate((attr_matrix_test, amatrix_test), axis=1)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(\"     X : \", X.shape)\n",
    "print(\"     y : \", y.shape)\n",
    "print(\"Test:\")\n",
    "print(\"     X : \", X_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25793x26147 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3009689 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "X = sparse.csr_matrix(X)\n",
    "X_kaggle = sparse.csr_matrix(X_kaggle)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "\n",
    "        yhat = model.predict(X_test)\n",
    "        yhat = yhat.round()\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "\n",
    "        print('>%.3f' % acc)\n",
    "        results.append(acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 20), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15b183a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "model = get_model(n_inputs, n_outputs)\n",
    "\n",
    "model.fit(X_train, y_train, verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "541/541 [==============================] - 1s 1ms/step\n",
      "266/266 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, recall_score, f1_score\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_column(matrix):\n",
    "    \n",
    "    n_samples, n_class = matrix.shape\n",
    "    # print(n_samples, n_class)\n",
    "\n",
    "    output =[]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        pred = \"\"\n",
    "        for j in range(n_class):\n",
    "            if matrix[i][j] >= 0.99999:\n",
    "                pred += str(j) + \" \"\n",
    "        if pred:\n",
    "            output.append(pred[:-1])\n",
    "        else:\n",
    "            output.append(\"-1\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8512, 100)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = multi_label_column(y_train)\n",
    "y_pred_train_list = multi_label_column(y_pred_train)\n",
    "\n",
    "y_test_list = multi_label_column(y_test)\n",
    "y_pred_list = multi_label_column(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Evaluation results=========================\n",
      "The accuracy score of prediction is: 0.7135808270676691\n",
      "The racall score of prediction is: 0.7135808270676691\n",
      "The f1 score of prediction is: 0.6105150709801721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('='*25 + 'Evaluation results' + '='*25)\n",
    "print('The accuracy score of prediction is: {}'.format(accuracy_score(y_test_list, y_pred_list)))\n",
    "print('The racall score of prediction is: {}'.format(recall_score(y_test_list, y_pred_list, average='weighted')))\n",
    "print('The f1 score of prediction is: {}'.format(f1_score(y_test_list, y_pred_list, average='weighted'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_output(model, X=X_kaggle):\n",
    "    y_pred = model.predict(X)\n",
    "    output_df = pd.DataFrame(columns=[\"ID\", \"Predict\"])\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        pred = \"\"\n",
    "        for j in range(y_pred.shape[1]):\n",
    "            if y_pred[i][j] > 0.99:\n",
    "                pred += str(j) + \" \"\n",
    "        if pred:\n",
    "            output_df.loc[i, 'Predict'] = pred[:-1]\n",
    "        else:\n",
    "            output_df.loc[i, 'Predict'] = \"-1\"\n",
    "\n",
    "    output_df['ID'] = output_df.index\n",
    "    output_df = output_df.set_index('ID')\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# count / length\n",
    "kaggle = kaggle_output(model)\n",
    "kaggle.to_csv(\"../kaggle/predict3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = pd.read_csv('../kaggle/predict2.csv')\n",
    "p3 = pd.read_csv('../kaggle/predict3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p2['Predict'] == p3['Predict'])/len(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "84\n",
      "66\n",
      "23 47 96\n",
      "42\n",
      "45\n",
      "3 36 42\n",
      "45 74\n",
      "10\n",
      "38\n",
      "14 26\n",
      "5\n",
      "12\n",
      "94\n",
      "81\n",
      "32\n",
      "41 88\n",
      "74\n",
      "53 68\n",
      "75\n",
      "99\n",
      "25 82\n",
      "99\n",
      "74\n",
      "81\n",
      "12 60\n",
      "30 50\n",
      "36\n",
      "25 30\n",
      "97\n",
      "37\n",
      "74\n",
      "49\n",
      "10\n",
      "11\n",
      "38\n",
      "78\n",
      "43\n",
      "36\n",
      "45\n",
      "74\n",
      "45\n",
      "57\n",
      "36 89\n",
      "97\n",
      "34 44\n",
      "78\n",
      "19\n",
      "12 77\n",
      "38\n",
      "38\n",
      "12\n",
      "60 73\n",
      "66\n",
      "0 34\n",
      "69 80\n",
      "33 61 71\n",
      "45\n",
      "23\n",
      "90\n",
      "78\n",
      "32 57\n",
      "0 34\n",
      "43 56\n",
      "97 99\n"
     ]
    }
   ],
   "source": [
    "for pred in p3['Predict']:\n",
    "    if pred != \"-1\":\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
