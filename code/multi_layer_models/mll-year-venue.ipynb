{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import make_multilabel_classification\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from preprocessing import for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "delet some useless data: 100%|██████████| 25793/25793 [00:00<00:00, 363460.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instance with label :  7460\n",
      "Number of instance without label(remain) :  1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "venue: 100%|██████████| 25793/25793 [00:05<00:00, 4686.97it/s]\n",
      "year: 100%|██████████| 25793/25793 [00:04<00:00, 5601.65it/s]\n",
      "authors: 100%|██████████| 25793/25793 [00:05<00:00, 4440.98it/s]\n"
     ]
    }
   ],
   "source": [
    "X, y = for_train(\"year_venue\", p=0.20250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9354, 486])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "\n",
    "N_FEATURES = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "     X_train :  torch.Size([7483, 486])\n",
      "     y_train :  torch.Size([7483, 100])\n",
      "Test_Kaggle:\n",
      "     X_test  :  torch.Size([1871, 486])\n",
      "     y_test  :  torch.Size([1871, 100])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# X_train = X\n",
    "# X_test = X\n",
    "# y_train = y\n",
    "# y_test = y\n",
    "\n",
    "print(\"Train:\")\n",
    "print(\"     X_train : \", X_train.shape)\n",
    "print(\"     y_train : \", y_train.shape)\n",
    "print(\"Test_Kaggle:\")\n",
    "print(\"     X_test  : \", X_test.shape)\n",
    "print(\"     y_test  : \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_Models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of training samples: 7483\n",
      "[INFO]: Number of training features: 486\n"
     ]
    }
   ],
   "source": [
    "print(f\"[INFO]: Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"[INFO]: Number of training features: {X_train.shape[1]}\")\n",
    "\n",
    "# train data loader\n",
    "train_dataset, train_dataloader = BinaryDataLoader(X_train, y_train, shuffle=True, batch_size=100)\n",
    "\n",
    "# initialize the model\n",
    "model = NeuralNetworkYearVenue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkYearVenue(\n",
       "  (fc1): Linear(in_features=486, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.001\n",
    "loss_func = \"BCE\"\n",
    "\n",
    "# learning parameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate) # 学习率衰减 / 学习率震荡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 100\n",
    "\n",
    "# load the model on to the computation device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs        : 100 \n",
      "learning rate : 0.001\n",
      "loss function : BCE\n",
      "NeuralNetworkYearVenue(\n",
      "  (fc1): Linear(in_features=486, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (out): Linear(in_features=128, out_features=100, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [10:44<00:00,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "644.1037991046906 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# start the training\n",
    "start = time.time()\n",
    "train_loss = []\n",
    "print(f\"Epochs        : {epochs} \")\n",
    "print(f\"learning rate : {learning_rate}\")\n",
    "print(f\"loss function : {loss_func}\")\n",
    "print(model)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    train_epoch_loss = train(\n",
    "        model, train_dataloader, optimizer, loss_fn, train_dataset, device, loss_func=loss_func\n",
    "    )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    # print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "torch.save(model.state_dict(), 'status/model_year_venue.pth')\n",
    "\n",
    "print(\"=\"*25)\n",
    "print(time.time()-start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# plot and save the train loss graph\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "# plt.savefig('outputs/multi_head_binary_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test (ignore when submit kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of testing samples: 9354\n",
      "[INFO]: Number of testing features: 4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "delet some useless data: 100%|██████████| 25793/25793 [00:00<00:00, 30759.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instance with label :  7460\n",
      "Number of instance without label(remain) :  1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "venue: 100%|██████████| 25793/25793 [00:03<00:00, 7442.46it/s] \n",
      "year: 100%|██████████| 25793/25793 [00:03<00:00, 8032.16it/s] \n",
      "authors: 100%|██████████| 25793/25793 [00:03<00:00, 6782.49it/s] \n"
     ]
    }
   ],
   "source": [
    "# print some info\n",
    "print(f\"[INFO]: Number of testing samples: {X_test.shape[0]}\")\n",
    "print(f\"[INFO]: Number of testing features: {X_test.shape[1]}\")\n",
    "\n",
    "# train data loader\n",
    "X_test, y_test = for_train(\"year_venue\", p=0.20250)\n",
    "\n",
    "test_dataset, test_dataloader = BinaryDataLoader(X_test, y_test, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetworkYearVenue(\n",
       "  (fc1): Linear(in_features=486, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetworkYearVenue()\n",
    "model.load_state_dict(torch.load('status/model_year_venue.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import *\n",
    "\n",
    "target_list = transform_labels(y_test, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "def get_f1(threshold):\n",
    "    predict_list = []\n",
    "\n",
    "    for i, test_sample in enumerate(test_dataloader):\n",
    "        \n",
    "        features = test_sample['features']\n",
    "        \n",
    "        \n",
    "        features = torch.reshape(features, (features.shape[0], 1, features.shape[1])).to(device)\n",
    "        \n",
    "        outputs = model(features)\n",
    "        \n",
    "        outputs = outputs.squeeze()\n",
    "                \n",
    "        # get all the labels\n",
    "        predict_list.append(transform_to_label(outputs, threshold=threshold))\n",
    "\n",
    "    return predict_list, f1_score(target_list, predict_list, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [03:13<00:00, 21.51s/it]\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "f1_scores = []\n",
    "\n",
    "for i in tqdm(range(len(thresholds))):\n",
    "    threshold = thresholds[i]\n",
    "\n",
    "    predict_list, f1 = get_f1(threshold)\n",
    "\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD = thresholds[f1_scores.index(max(f1_scores))]\n",
    "THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04941159892404381,\n",
       " 0.06857969789130361,\n",
       " 0.1028284782353225,\n",
       " 0.10363675985590383,\n",
       " 0.09221757716878314,\n",
       " 0.08101750448001468,\n",
       " 0.07688663410024721,\n",
       " 0.07562572802183185,\n",
       " 0.0733221240762623]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max(f1_scores)\n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "venue: 100%|██████████| 800/800 [00:00<00:00, 105706.56it/s]\n",
      "year: 100%|██████████| 800/800 [00:00<00:00, 132343.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of testing samples: 800\n",
      "[INFO]: Number of testing features: 486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:00<00:00, 1537.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import for_kaggle\n",
    "\n",
    "X_kaggle = for_kaggle('year_venue')\n",
    "\n",
    "# print some info\n",
    "print(f\"[INFO]: Number of testing samples: {X_kaggle.shape[0]}\")\n",
    "print(f\"[INFO]: Number of testing features: {X_kaggle.shape[1]}\")\n",
    "\n",
    "# train data loader\n",
    "kaggle_dataloader = BinaryDataLoader(X_kaggle, None, shuffle=False, batch_size=1)\n",
    "\n",
    "predict_dict = {}\n",
    "\n",
    "# for i, test_sample in tqdm(enumerate(kaggle_dataloader), total=len(kaggle_dataloader)):\n",
    "key = 0\n",
    "for test_sample in tqdm(X_kaggle):\n",
    "    # print(f\"SAMPLE {i}\")\n",
    "    # extract the features and labels\n",
    "    features = test_sample\n",
    "    \n",
    "    outputs = model(features)\n",
    "    outputs = outputs.squeeze()\n",
    "    tmp = {}\n",
    "    \n",
    "    for i in range(100):\n",
    "        tmp[i] = outputs[i].item()\n",
    "         \n",
    "    predict_dict[key] = tmp\n",
    "    \n",
    "    key += 1\n",
    "\n",
    "with open('outputs/year_venue.json', 'w') as fp:\n",
    "    json.dump(predict_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
