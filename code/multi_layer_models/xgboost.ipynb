{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 00:23:59.783790: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "from preprocessing import for_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "delet some useless data: 100%|██████████| 25793/25793 [00:00<00:00, 901350.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instance with label :  7460\n",
      "Number of instance without label(remain) :  1894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "authors: 100%|██████████| 25793/25793 [00:04<00:00, 6231.75it/s]\n",
      "venue: 100%|██████████| 25793/25793 [00:04<00:00, 6314.19it/s]\n",
      "year: 100%|██████████| 25793/25793 [00:04<00:00, 6064.80it/s]\n"
     ]
    }
   ],
   "source": [
    "f_train = open(\"../../data/train.json\", 'r')\n",
    "train_data = json.load(f_train)\n",
    "\n",
    "def find_discard_authors(data, p):\n",
    "    # p = 0.20250\n",
    "    # p = -1\n",
    "\n",
    "    n_samples = len(data)\n",
    "    empty_idx = []\n",
    "    if p == -1:\n",
    "        return []\n",
    "\n",
    "    for i in tqdm(range(n_samples), desc=\"delet some useless data\"):\n",
    "        authors = data[i]['authors']\n",
    "        p_author = 0\n",
    "\n",
    "        for au in authors:\n",
    "            if au < 100:\n",
    "                p_author += 1\n",
    "        \n",
    "        if p_author == 0:\n",
    "            empty_idx.append(i)\n",
    "    \n",
    "    print(\"Number of instance with label : \", n_samples-len(empty_idx))\n",
    "    \n",
    "    remain = int((p*(n_samples-len(empty_idx))/(1-p)))\n",
    "    \n",
    "    print(\"Number of instance without label(remain) : \", remain)\n",
    "\n",
    "    return random.sample(empty_idx, len(empty_idx) - remain)\n",
    "\n",
    "def get_author_matrix(data, discard_idx=[], train=True):\n",
    "    n_samples = len(data)\n",
    "\n",
    "    # get prolific authors \n",
    "    # co author -> feature / 单独编码\n",
    "    # 多任务 - predict all authors \n",
    "\n",
    "\n",
    "    if train:\n",
    "        y = np.ndarray([n_samples-len(discard_idx), 100])\n",
    "        key = 'authors'\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    # get co-author matrix\n",
    "    if train:\n",
    "        amatrix = np.ndarray([n_samples-len(discard_idx), 21245 - 100 + 1])\n",
    "    else:\n",
    "        amatrix = np.ndarray([n_samples, 21245 - 100 + 1])\n",
    "        key = 'coauthors'\n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"authors\"):\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        authors = data[i][key]\n",
    "        \n",
    "        for au in authors:\n",
    "            if au < 100:\n",
    "                y[INDEX, au] += 1\n",
    "\n",
    "            else:\n",
    "                amatrix[INDEX, au - 100] += 1\n",
    "\n",
    "        INDEX += 1\n",
    "        \n",
    "    return amatrix, y\n",
    "\n",
    "def get_year_venue_matrix(data, discard_idx=[], train=True):\n",
    "    n_samples = len(data)\n",
    "\n",
    "    # get venue feature\n",
    "    # embedding\n",
    "\n",
    "    if train:\n",
    "        vmatrix = np.ndarray([n_samples-len(discard_idx), 466])\n",
    "    else:\n",
    "        vmatrix = np.ndarray([n_samples, 466])\n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"venue\"):\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        venue = data[i]['venue']\n",
    "        \n",
    "        if venue:\n",
    "            vmatrix[INDEX, venue] = 1\n",
    "        else:\n",
    "            vmatrix[INDEX, 465] = 1\n",
    "        INDEX += 1\n",
    "\n",
    "    if train:\n",
    "        ymatrix = np.ndarray([n_samples-len(discard_idx), 20])\n",
    "    else:\n",
    "        ymatrix = np.ndarray([n_samples, 20])\n",
    "    \n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"year\"):\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        year = data[INDEX]['year']\n",
    "        \n",
    "        if year:\n",
    "            ymatrix[INDEX, year] = 1\n",
    "        else:\n",
    "            ymatrix[INDEX, year] = 0\n",
    "        INDEX += 1\n",
    "\n",
    "    return np.concatenate((vmatrix, ymatrix), 1)\n",
    "\n",
    "\n",
    "di = find_discard_authors(train_data, p=0.20250)\n",
    "_, y = get_author_matrix(train_data, di)\n",
    "X = get_year_venue_matrix(train_data, di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "     X_train :  (7483, 486)\n",
      "     y_train :  (7483, 100)\n",
      "Test_Kaggle:\n",
      "     X_test  :  (1871, 486)\n",
      "     y_test  :  (1871, 100)\n"
     ]
    }
   ],
   "source": [
    "# y_1 = y[:, 1:5]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "# X_train = X\n",
    "# X_test = X\n",
    "# y_train = y\n",
    "# y_test = y\n",
    "\n",
    "print(\"Train:\")\n",
    "print(\"     X_train : \", X_train.shape)\n",
    "print(\"     y_train : \", y_train.shape)\n",
    "print(\"Test_Kaggle:\")\n",
    "print(\"     X_test  : \", X_test.shape)\n",
    "print(\"     y_test  : \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def evaluate_model(X, y):\n",
    "    results = list()\n",
    "    n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "    for train_ix, test_ix in cv.split(X):\n",
    "\n",
    "        X_train, X_test = X[train_ix], X[test_ix]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "        model = get_model(n_inputs, n_outputs)\n",
    "\n",
    "        model.fit(X_train, y_train, verbose=0, epochs=100)\n",
    "\n",
    "        yhat = model.predict(X_test)\n",
    "        yhat = yhat.round()\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "\n",
    "        print('>%.3f' % acc)\n",
    "        results.append(acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16c33ba90>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "\n",
    "n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\n",
    "model = get_model(n_inputs, n_outputs)\n",
    "\n",
    "model.fit(X_train, y_train, verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 1s 2ms/step\n",
      "59/59 [==============================] - 0s 943us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, recall_score, f1_score\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_column(matrix):\n",
    "    \n",
    "    n_samples, n_class = matrix.shape\n",
    "    # print(n_samples, n_class)\n",
    "\n",
    "    output =[]\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        pred = \"\"\n",
    "        for j in range(n_class):\n",
    "            if matrix[i][j] >= 0.1:\n",
    "                pred += str(j) + \" \"\n",
    "        if pred:\n",
    "            output.append(pred[:-1])\n",
    "        else:\n",
    "            output.append(\"-1\")\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1871, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = multi_label_column(y_train)\n",
    "y_pred_train_list = multi_label_column(y_pred_train)\n",
    "\n",
    "y_test_list = multi_label_column(y_test)\n",
    "y_pred_list = multi_label_column(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Evaluation results=========================\n",
      "The accuracy score of prediction is: 0.15713522180652056\n",
      "The racall score of prediction is: 0.15713522180652056\n",
      "The f1 score of prediction is: 0.07426359420270866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('='*25 + 'Evaluation results' + '='*25)\n",
    "print('The accuracy score of prediction is: {}'.format(accuracy_score(y_test_list, y_pred_list)))\n",
    "print('The racall score of prediction is: {}'.format(recall_score(y_test_list, y_pred_list, average='weighted')))\n",
    "print('The f1 score of prediction is: {}'.format(f1_score(y_test_list, y_pred_list, average='weighted'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1210119e-03, 6.7151412e-03, 8.5109333e-03, ..., 2.0335540e-02,\n",
       "        1.0140832e-02, 1.0872827e-02],\n",
       "       [3.8836230e-02, 2.5586510e-02, 6.6189835e-04, ..., 2.3895851e-03,\n",
       "        1.1077715e-03, 2.5966848e-04],\n",
       "       [1.3430017e-02, 1.0919531e-02, 4.4666328e-03, ..., 4.8015043e-03,\n",
       "        3.0004121e-03, 2.7487981e-03],\n",
       "       ...,\n",
       "       [6.6489474e-06, 2.8531868e-03, 3.0807371e-03, ..., 7.3693544e-03,\n",
       "        1.0027222e-02, 6.6739781e-04],\n",
       "       [4.2460905e-03, 4.4979141e-03, 1.1782616e-02, ..., 1.1800103e-02,\n",
       "        6.0533406e-03, 2.2307139e-02],\n",
       "       [5.7770931e-03, 5.2451496e-03, 1.0570733e-02, ..., 1.0764746e-02,\n",
       "        4.2453292e-03, 1.7640496e-02]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None, max_bin=None,\n",
       "                                            max_cat_to_onehot=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            max_leaves=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None, ...))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create XGBoost instance with default hyper-parameters\n",
    "xgb_estimator = xgb.XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "# create MultiOutputClassifier instance with XGBoost model inside\n",
    "multilabel_model = OneVsRestClassifier(xgb_estimator)\n",
    "\n",
    "# fit the model\n",
    "multilabel_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.9690005344735435\n",
      "recall   :  0.017543859649122806\n",
      "f1       :  0.03070175438596491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "y_pred = multilabel_model.predict(X_test)\n",
    "\n",
    "print(\"accuracy : \", accuracy_score(y_test, y_pred))\n",
    "print(\"recall   : \", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"f1       : \", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "       [1.89240875e-052, 4.90750276e-062, 1.78800382e-052, ...,\n",
       "        0.00000000e+000, 1.00000000e+000, 0.00000000e+000],\n",
       "       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "       ...,\n",
       "       [4.57672550e-072, 5.15146484e-062, 1.18051609e-095, ...,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "       [1.18014677e-095, 2.99939715e-067, 1.20253480e+285, ...,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "       [9.50277535e-043, 1.08651609e-095, 4.57668662e-072, ...,\n",
       "        0.00000000e+000, 0.00000000e+000, 0.00000000e+000]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = make_multilabel_classification(n_samples=3000, n_features=45, n_classes=20, n_labels=1,\n",
    "                                      allow_unlabeled=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7483, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
