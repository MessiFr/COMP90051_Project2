{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import make_multilabel_classification\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "delet some useless data: 100%|██████████| 25793/25793 [00:00<00:00, 465486.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "title & abstract: 100%|██████████| 25793/25793 [00:31<00:00, 814.60it/s] \n",
      "venue: 100%|██████████| 25793/25793 [00:02<00:00, 11240.97it/s]\n",
      "year: 100%|██████████| 25793/25793 [00:02<00:00, 10840.07it/s]\n",
      "authors: 100%|██████████| 25793/25793 [00:02<00:00, 9391.54it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "title & abstract: 100%|██████████| 800/800 [00:01<00:00, 447.07it/s]\n",
      "venue: 100%|██████████| 800/800 [00:00<00:00, 150353.69it/s]\n",
      "year: 100%|██████████| 800/800 [00:00<00:00, 192167.87it/s]\n",
      "authors: 100%|██████████| 800/800 [00:00<00:00, 25132.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "     X :  torch.Size([14920, 26147])\n",
      "     y :  torch.Size([14920, 100])\n",
      "Test_Kaggle:\n",
      "     X :  torch.Size([800, 26147])\n"
     ]
    }
   ],
   "source": [
    "# read train data and test data\n",
    "f_train = open(\"../data/train.json\", 'r')\n",
    "train_data = json.load(f_train)\n",
    "\n",
    "f_test = open(\"../data/test.json\", 'r')\n",
    "test_data = json.load(f_test)\n",
    "\n",
    "\n",
    "def handle_authors(data):\n",
    "    n_samples = len(data)\n",
    "    empty_idx = []\n",
    "\n",
    "    for i in tqdm(range(n_samples), desc=\"delet some useless data\"):\n",
    "        authors = data[i]['authors']\n",
    "        p_author = 0\n",
    "\n",
    "        for au in authors:\n",
    "            if au < 100:\n",
    "                p_author += 1\n",
    "        \n",
    "        if p_author == 0:\n",
    "            empty_idx.append(i)\n",
    "    \n",
    "    discard_idx = empty_idx[:len(empty_idx)-(n_samples-len(empty_idx))]\n",
    "\n",
    "    return discard_idx\n",
    "\n",
    "\n",
    "def get_attr_matrix(data, discard_idx=[], train=True):\n",
    "    n_samples = len(data)\n",
    "    n_features = 5000 -1 \n",
    "\n",
    "    # get abstract & title feature\n",
    "    # 序列信息 ！！！！\n",
    "    # 语言模型\n",
    "    # lstm （*）\n",
    "\n",
    "    #   XX bert pre-trained / 去掉embedding层 **\n",
    "\n",
    "\n",
    "    if train:\n",
    "        wmatrix = torch.zeros([n_samples-len(discard_idx), n_features])\n",
    "    else:\n",
    "        wmatrix = torch.zeros([n_samples, n_features])\n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"title & abstract\"):\n",
    "\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        instance = data[INDEX]\n",
    "        for title in instance['title']:\n",
    "            wmatrix[INDEX, title-1] += 1\n",
    "        for abstract in instance['abstract']:\n",
    "            wmatrix[INDEX, abstract-1] += 1\n",
    "        INDEX += 1\n",
    "\n",
    "    # get venue feature\n",
    "    # embedding\n",
    "\n",
    "    if train:\n",
    "        vmatrix = torch.zeros([n_samples-len(discard_idx), 1])\n",
    "    else:\n",
    "        vmatrix = torch.zeros([n_samples, 1])\n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"venue\"):\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        venue = data[INDEX]['venue']\n",
    "        \n",
    "        if venue:\n",
    "            vmatrix[INDEX, ] = venue\n",
    "        else:\n",
    "            vmatrix[INDEX, ] = -1\n",
    "        INDEX += 1\n",
    "\n",
    "    # get year feature !!!!!\n",
    "    # 1-d 编码器 年份 输出特征 -》 256维\n",
    "    # distribution of \n",
    "    # nn.Embedding() // input: batch-size * 1 // output: batch-size * embedding-size\n",
    "\n",
    "    if train:\n",
    "        ymatrix = torch.zeros([n_samples-len(discard_idx), 1])\n",
    "    else:\n",
    "        ymatrix = torch.zeros([n_samples, 1])\n",
    "    \n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"year\"):\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        year = data[INDEX]['year']\n",
    "        \n",
    "        if year:\n",
    "            ymatrix[INDEX, ] = year\n",
    "        else:\n",
    "            ymatrix[INDEX, ] = -1\n",
    "        INDEX += 1\n",
    "\n",
    "    # get prolific authors \n",
    "    # co author -> feature / 单独编码\n",
    "    # 多任务 - predict all authors \n",
    "\n",
    "\n",
    "    if train:\n",
    "        y = torch.zeros([n_samples-len(discard_idx), 100])\n",
    "        key = 'authors'\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    # get co-author matrix\n",
    "    if train:\n",
    "        amatrix = torch.zeros([n_samples-len(discard_idx), 21245 - 100 + 1])\n",
    "    else:\n",
    "        amatrix = torch.zeros([n_samples, 21245 - 100 + 1])\n",
    "        key = 'coauthors'\n",
    "\n",
    "    INDEX = 0\n",
    "    for i in tqdm(range(n_samples), desc=\"authors\"):\n",
    "        if i in discard_idx and train:\n",
    "            continue\n",
    "\n",
    "        authors = data[INDEX][key]\n",
    "        p_author = 0\n",
    "        \n",
    "        for au in authors:\n",
    "            if au < 100:\n",
    "                y[INDEX, au] += 1\n",
    "\n",
    "            else:\n",
    "                amatrix[INDEX, au - 100] += 1\n",
    "\n",
    "        INDEX += 1\n",
    "            \n",
    "    return torch.cat((wmatrix, vmatrix, ymatrix, amatrix), 1), y\n",
    "\n",
    "di = handle_authors(train_data)\n",
    "\n",
    "print(\"Train Data\")\n",
    "X, y = get_attr_matrix(train_data, discard_idx=di)\n",
    "\n",
    "print(\"Test Data\")\n",
    "X_kaggle, _ = get_attr_matrix(test_data, train=False)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(\"     X : \", X.shape)\n",
    "print(\"     y : \", y.shape)\n",
    "print(\"Test_Kaggle:\")\n",
    "print(\"     X : \", X_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "     X_train :  torch.Size([9996, 26147])\n",
      "     y_train :  torch.Size([9996, 100])\n",
      "Test_Kaggle:\n",
      "     X_test  :  torch.Size([4924, 26147])\n",
      "     y_test  :  torch.Size([4924, 100])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "print(\"Train:\")\n",
    "print(\"     X_train : \", X_train.shape)\n",
    "print(\"     y_train : \", y_train.shape)\n",
    "print(\"Test_Kaggle:\")\n",
    "print(\"     X_test  : \", X_test.shape)\n",
    "print(\"     y_test  : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `BinaryDataset()` class for multi-head binary classification model\n",
    "class BinaryDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        features = self.x[index, :]\n",
    "        labels = self.y[index, :]\n",
    "        \n",
    "        # we have 12 feature columns \n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "        # there are 5 classes and each class can have a binary value ...\n",
    "        # ... either 0 or 1\n",
    "        label_dict = {'features': features}\n",
    "        for i in range(100):\n",
    "            key = 'label' + str(i)\n",
    "            label_dict[key] = torch.tensor(labels[i], dtype=torch.float32)\n",
    "\n",
    "        return label_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 多个class /  - 特征融合 - 过全联接层 - 输出层\n",
    "## 多输出 融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadBinaryModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadBinaryModel, self).__init__()\n",
    "\n",
    "        ## 1024, 512, 256, 100\n",
    "        ## nn.Dropout() // 0.1, 0.2 //\n",
    "\n",
    "        self.fc1 = nn.Linear(26147, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.out = nn.Linear(512, 100)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # F.leaky_relu()\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        outs = F.sigmoid(self.out(x)) \n",
    "\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# custom loss function for multi-head binary classification\n",
    "# binary_loss_fn\n",
    "def loss_fn(outputs, targets):\n",
    "\n",
    "    n_class = 100\n",
    "    sum_ = 0\n",
    "    \n",
    "    for i in range(n_class):\n",
    "        \n",
    "        # outputs_ = torch.reshape(outputs[i], (-1,))\n",
    "        outputs_ = outputs[:, i]\n",
    "\n",
    "        '''for j in range(len(outputs_)):\n",
    "\n",
    "            ## threshold !!!!!!!!\n",
    "            ## threshold \n",
    "            ## 每个人阈值不同，>0.5, 降低threshold, \n",
    "            ## 0.2 ? (0.1) => recall\n",
    "            \n",
    "            if outputs_[j] > 0.2:\n",
    "                outputs_[j] = 1\n",
    "            else:\n",
    "                outputs_[j] = 0'''\n",
    "        \n",
    "        sum_ += nn.BCELoss()(outputs_, targets[i])\n",
    "        ## 多标签分类 (mse) \n",
    "\n",
    "    return sum_ / n_class\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dataset import make_dataset, BinaryDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of training samples: 9996\n",
      "[INFO]: Number of training features: 26147\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "# x_train, y_train, _, _ = make_dataset()\n",
    "# print some info\n",
    "print(f\"[INFO]: Number of training samples: {X_train.shape[0]}\")\n",
    "print(f\"[INFO]: Number of training features: {X_train.shape[1]}\")\n",
    "# train dataset\n",
    "train_dataset = BinaryDataset(X_train, y_train)\n",
    "# train data loader\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=1024)\n",
    "# initialize the model\n",
    "model = MultiHeadBinaryModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(model, dataloader, optimizer, loss_fn, train_dataset, device):\n",
    "    model.train()\n",
    "    counter = 0\n",
    "    train_running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_dataset)/dataloader.batch_size)):\n",
    "    \n",
    "        counter += 1\n",
    "        \n",
    "        # extract the features and labels\n",
    "        features = data['features'].to(device)\n",
    "        \n",
    "        targets = []\n",
    "        for j in range(100):\n",
    "            targets.append(data[f'label{j}'].to(device))\n",
    "        \n",
    "        # zero-out the optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(features)\n",
    "        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        train_running_loss += loss.item()\n",
    "        \n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # update optimizer parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = train_running_loss / counter\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadBinaryModel(\n",
       "  (fc1): Linear(in_features=26147, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (out): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning parameters\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=0.001) # 学习率衰减 / 学习率震荡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "epochs = 10\n",
    "# load the model on to the computation device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]/var/folders/v7/wxn3bxmn2018mjps58z5d3hw0000gn/T/ipykernel_17049/3191504715.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(features, dtype=torch.float32)\n",
      "/var/folders/v7/wxn3bxmn2018mjps58z5d3hw0000gn/T/ipykernel_17049/3191504715.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_dict[key] = torch.tensor(labels[i], dtype=torch.float32)\n",
      "10it [00:32,  3.23s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0510\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:25,  2.59s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0341\n",
      "Epoch 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:29,  2.96s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0285\n",
      "Epoch 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:30,  3.04s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0262\n",
      "Epoch 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:28,  2.84s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0239\n",
      "Epoch 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:26,  2.64s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0223\n",
      "Epoch 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:25,  2.56s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0210\n",
      "Epoch 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:25,  2.51s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0198\n",
      "Epoch 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:29,  3.00s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0186\n",
      "Epoch 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:26,  2.69s/it]                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0173\n",
      "=== Running duration ===\n",
      "281.59160900115967 s\n"
     ]
    }
   ],
   "source": [
    "# start the training\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "    train_epoch_loss = train(\n",
    "        model, train_dataloader, optimizer, loss_fn, train_dataset, device\n",
    "    )\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "torch.save(model.state_dict(), 'outputs/multi_head_binary.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'outputs/multi_head_binary_epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of testing samples: 4924\n",
      "[INFO]: Number of testing features: 26147\n"
     ]
    }
   ],
   "source": [
    "# print some info\n",
    "print(f\"[INFO]: Number of testing samples: {X_test.shape[0]}\")\n",
    "print(f\"[INFO]: Number of testing features: {X_test.shape[1]}\")\n",
    "# train dataset\n",
    "test_dataset = BinaryDataset(X_test, y_test)\n",
    "# train data loader\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadBinaryModel(\n",
       "  (fc1): Linear(in_features=26147, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (out): Linear(in_features=512, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiHeadBinaryModel()\n",
    "model = MultiHeadBinaryModel()\n",
    "model.load_state_dict(torch.load('outputs/multi_head_binary_epoch.pth'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_list = []\n",
    "for i in range(y_test.shape[0]):\n",
    "    tmp = \"\"\n",
    "    for j in range(100):\n",
    "        if y_test[i][j] > 0.5:\n",
    "            tmp += str(j) + \" \"\n",
    "    if tmp:\n",
    "        target_label_list.append(tmp[: -1])\n",
    "    else:\n",
    "        target_label_list.append(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4924 [00:00<?, ?it/s]/var/folders/v7/wxn3bxmn2018mjps58z5d3hw0000gn/T/ipykernel_17049/3191504715.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  features = torch.tensor(features, dtype=torch.float32)\n",
      "/var/folders/v7/wxn3bxmn2018mjps58z5d3hw0000gn/T/ipykernel_17049/3191504715.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label_dict[key] = torch.tensor(labels[i], dtype=torch.float32)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 4924/4924 [00:36<00:00, 136.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running duration ===\n",
      "36.15157175064087 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "predict_list = []\n",
    "\n",
    "for i, test_sample in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "    # print(f\"SAMPLE {i}\")\n",
    "    # extract the features and labels\n",
    "    features = test_sample['features'].to(device)\n",
    "    \n",
    "    outputs = model(features)\n",
    "\n",
    "    outputs = outputs.squeeze()\n",
    "            \n",
    "    # get all the labels\n",
    "    all_labels = []\n",
    "    for out in outputs:\n",
    "        # Threshold set to 0.2\n",
    "        if out >= 0.8:\n",
    "            all_labels.append(1)\n",
    "        else:\n",
    "            all_labels.append(0)\n",
    "    \n",
    "    tmp_ = \"\"\n",
    "    for j in range(100):\n",
    "        if all_labels[j] == 1:\n",
    "            tmp_ += str(j) + \" \"\n",
    "    if tmp_:\n",
    "        predict_list.append(tmp_[:-1])\n",
    "    else:\n",
    "        predict_list.append(\"-1\")\n",
    "        \n",
    "    \n",
    "print(\"=== Running duration ===\")\n",
    "print(time.time() - start, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Evaluation results=========================\n",
      "The accuracy score of prediction is : 0.7175060926076361\n",
      "The recall   score of prediction is : 0.7175060926076361\n",
      "The f1       score of prediction is : 0.5994913149303012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "print('='*25 + 'Evaluation results' + '='*25)\n",
    "print('The accuracy score of prediction is : {}'.format(accuracy_score(target_label_list, predict_list)))\n",
    "print('The recall   score of prediction is : {}'.format(recall_score(target_label_list, predict_list, average='weighted')))\n",
    "print('The f1       score of prediction is : {}'.format(f1_score(target_label_list, predict_list, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and save the train loss graph\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('outputs/multi_head_binary_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Number of testing samples: 800\n",
      "[INFO]: Number of testing features: 26147\n"
     ]
    }
   ],
   "source": [
    "# print some info\n",
    "print(f\"[INFO]: Number of testing samples: {X_kaggle.shape[0]}\")\n",
    "print(f\"[INFO]: Number of testing features: {X_kaggle.shape[1]}\")\n",
    "# train dataset\n",
    "kaggle_dataset = BinaryDataset(X_kaggle, _)\n",
    "# train data loader\n",
    "kaggle_dataloader = DataLoader(kaggle_dataset, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 800/800 [00:05<00:00, 151.07it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_list_kaggle = []\n",
    "\n",
    "# for i, test_sample in tqdm(enumerate(kaggle_dataloader), total=len(kaggle_dataloader)):\n",
    "for test_sample in tqdm(X_kaggle):\n",
    "    # print(f\"SAMPLE {i}\")\n",
    "    # extract the features and labels\n",
    "    features = test_sample\n",
    "    \n",
    "    outputs = model(features)\n",
    "\n",
    "    outputs = outputs.squeeze()\n",
    "            \n",
    "    # get all the labels\n",
    "    all_labels = []\n",
    "    for out in outputs:\n",
    "        # Threshold set to 0.2\n",
    "        if out >= 0.67:\n",
    "            all_labels.append(1)\n",
    "        else:\n",
    "            all_labels.append(0)\n",
    "    \n",
    "    tmp_ = \"\"\n",
    "    for j in range(100):\n",
    "        if all_labels[j] == 1:\n",
    "            tmp_ += str(j) + \" \"\n",
    "    if tmp_:\n",
    "        predict_list_kaggle.append(tmp_[:-1])\n",
    "    else:\n",
    "        predict_list_kaggle.append(\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def kaggle_output(predicts):\n",
    "    \n",
    "    output_df = pd.DataFrame(columns=[\"ID\", \"Predict\"])\n",
    "    output_df['Predict'] = predicts\n",
    "    output_df['ID'] = output_df.index\n",
    "    output_df = output_df.set_index('ID')\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = kaggle_output(predict_list_kaggle)\n",
    "kaggle.to_csv(\"../kaggle/predict5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "for i in kaggle['Predict']:\n",
    "    if i != '-1':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "max_ = 0\n",
    "\n",
    "for instance in test_data:\n",
    "    year = instance['year']\n",
    "    if year > max_:\n",
    "        max_ = year\n",
    "print(max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
